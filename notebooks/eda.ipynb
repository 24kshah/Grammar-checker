{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d6b67ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c05523f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../Grammar Correction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f70cb37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial Number</th>\n",
       "      <th>Error Type</th>\n",
       "      <th>Ungrammatical Statement</th>\n",
       "      <th>Standard English</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Verb Tense Errors</td>\n",
       "      <td>I goes to the store everyday.</td>\n",
       "      <td>I go to the store everyday.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Verb Tense Errors</td>\n",
       "      <td>They was playing soccer last night.</td>\n",
       "      <td>They were playing soccer last night.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Verb Tense Errors</td>\n",
       "      <td>She have completed her homework.</td>\n",
       "      <td>She has completed her homework.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Verb Tense Errors</td>\n",
       "      <td>He don't know the answer.</td>\n",
       "      <td>He doesn't know the answer.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Verb Tense Errors</td>\n",
       "      <td>The sun rise in the east.</td>\n",
       "      <td>The sun rises in the east.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Serial Number         Error Type              Ungrammatical Statement  \\\n",
       "0              1  Verb Tense Errors        I goes to the store everyday.   \n",
       "1              2  Verb Tense Errors  They was playing soccer last night.   \n",
       "2              3  Verb Tense Errors     She have completed her homework.   \n",
       "3              4  Verb Tense Errors            He don't know the answer.   \n",
       "4              5  Verb Tense Errors            The sun rise in the east.   \n",
       "\n",
       "                       Standard English  \n",
       "0           I go to the store everyday.  \n",
       "1  They were playing soccer last night.  \n",
       "2       She has completed her homework.  \n",
       "3           He doesn't know the answer.  \n",
       "4            The sun rises in the east.  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c0bab66",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = df.drop(columns=['Error Type','Serial Number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27939b5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ungrammatical Statement</th>\n",
       "      <th>Standard English</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I goes to the store everyday.</td>\n",
       "      <td>I go to the store everyday.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>They was playing soccer last night.</td>\n",
       "      <td>They were playing soccer last night.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>She have completed her homework.</td>\n",
       "      <td>She has completed her homework.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>He don't know the answer.</td>\n",
       "      <td>He doesn't know the answer.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The sun rise in the east.</td>\n",
       "      <td>The sun rises in the east.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Ungrammatical Statement                      Standard English\n",
       "0        I goes to the store everyday.           I go to the store everyday.\n",
       "1  They was playing soccer last night.  They were playing soccer last night.\n",
       "2     She have completed her homework.       She has completed her homework.\n",
       "3            He don't know the answer.           He doesn't know the answer.\n",
       "4            The sun rise in the east.            The sun rises in the east."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40a8ae49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\24ksh\\OneDrive\\Desktop\\grammer checker\\grammer\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\24ksh\\OneDrive\\Desktop\\grammer checker\\grammer\\lib\\site-packages\\tf_keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFT5ForConditionalGeneration.\n",
      "\n",
      "All the weights of TFT5ForConditionalGeneration were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "WARNING:tensorflow:From c:\\Users\\24ksh\\OneDrive\\Desktop\\grammer checker\\grammer\\lib\\site-packages\\tf_keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "404/404 [==============================] - 424s 986ms/step - loss: 0.8329 - val_loss: 0.2049\n",
      "Epoch 2/3\n",
      "404/404 [==============================] - 396s 980ms/step - loss: 0.1897 - val_loss: 0.1243\n",
      "Epoch 3/3\n",
      "404/404 [==============================] - 394s 974ms/step - loss: 0.0972 - val_loss: 0.0427\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./t5_grammar_corrector\\\\tokenizer_config.json',\n",
       " './t5_grammar_corrector\\\\special_tokens_map.json',\n",
       " './t5_grammar_corrector\\\\tokenizer.json')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from transformers import TFAutoModelForSeq2SeqLM, AutoTokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"../Grammar Correction.csv\")  # Update with your file path\n",
    "df = df[[\"Ungrammatical Statement\", \"Standard English\"]].dropna()\n",
    "\n",
    "# Rename for convenience\n",
    "df.columns = [\"input\", \"target\"]\n",
    "\n",
    "# Train/validation split\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    df[\"input\"].tolist(),\n",
    "    df[\"target\"].tolist(),\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Load model and tokenizer\n",
    "model_name = \"t5-small\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = TFAutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "# Tokenization function\n",
    "def tokenize_function(input_texts, target_texts):\n",
    "    inputs = tokenizer(\n",
    "        [\"fix grammar: \" + text for text in input_texts],\n",
    "        max_length=128,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        return_tensors=\"tf\"\n",
    "    )\n",
    "    targets = tokenizer(\n",
    "        target_texts,\n",
    "        max_length=128,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        return_tensors=\"tf\"\n",
    "    )\n",
    "    return inputs[\"input_ids\"], inputs[\"attention_mask\"], targets[\"input_ids\"]\n",
    "\n",
    "# Prepare TensorFlow dataset\n",
    "def create_tf_dataset(inputs, targets):\n",
    "    input_ids, attention_mask, label_ids = tokenize_function(inputs, targets)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((\n",
    "        {\n",
    "            \"input_ids\": input_ids,\n",
    "            \"attention_mask\": attention_mask\n",
    "        },\n",
    "        label_ids\n",
    "    ))\n",
    "    return dataset.shuffle(100).batch(4).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "train_dataset = create_tf_dataset(train_texts, train_labels)\n",
    "val_dataset = create_tf_dataset(val_texts, val_labels)\n",
    "\n",
    "# Compile the model\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)\n",
    "model.compile(optimizer=optimizer)\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_dataset, validation_data=val_dataset, epochs=3)\n",
    "\n",
    "# Save the model\n",
    "model.save_pretrained(\"./t5_grammar_corrector\")\n",
    "tokenizer.save_pretrained(\"./t5_grammar_corrector\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc1d9360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "She goes to school every day.\n"
     ]
    }
   ],
   "source": [
    "def correct_grammar(text):\n",
    "    input_text = \"fix grammar: \" + text\n",
    "    inputs = tokenizer(input_text, return_tensors=\"tf\", padding=\"max_length\", truncation=True, max_length=128)\n",
    "    output = model.generate(**inputs, max_length=128, num_beams=4)\n",
    "    return tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "# Example\n",
    "print(correct_grammar(\"She go to school every day.\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "072c4023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I go to school every day.\n",
      "He doesn't like mangoes.\n",
      "They were happy with the results.\n"
     ]
    }
   ],
   "source": [
    "print(correct_grammar(\"I goes to school every day\"))\n",
    "print(correct_grammar(\"He don't like mangoes\"))\n",
    "print(correct_grammar(\"They was happy with the results\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "05a1460d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(correct_grammar(\"where you are going\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1505a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "grammer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
